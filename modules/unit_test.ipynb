{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 128, 128])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dynext import MedNeXt2D\n",
    "import torch\n",
    "# Instantiate the MedNeXt2D block\n",
    "mednext_block = MedNeXt2D(in_channels=64)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(8, 64, 128, 128)  # (batch_size, channels, height, width)\n",
    "\n",
    "# Pass the input tensor through the MedNeXt2D block\n",
    "output_tensor = mednext_block(input_tensor)\n",
    "\n",
    "output_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from dynext import DyNeXt\n",
    "import torch\n",
    "# 初始化 DyNeXt 模块\n",
    "dynext_model = DyNeXt(in_channels=64, K=5)  # 64 通道输入，卷积核大小为 5x5\n",
    "\n",
    "# 创建一个输入张量 (batch_size, channels, height, width)\n",
    "input_tensor = torch.randn(8, 64, 128, 128)  # 例如: batch_size=8, channels=64, height=128, width=128\n",
    "\n",
    "# 通过 DyNeXt 模块进行前向传播\n",
    "output_tensor = dynext_model(input_tensor)\n",
    "\n",
    "# 打印输出张量的形状\n",
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PatchEmbed Output Shape: torch.Size([1, 3136, 96])\n",
      "SwinTransformerBlock Output Shape: torch.Size([1, 3136, 96])\n",
      "所有测试通过。\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from spvit import PatchEmbed, SwinTransformerBlock\n",
    "\n",
    "import torch\n",
    "\n",
    "def test_swin_transformer():\n",
    "    # 定义输入参数\n",
    "    img_size = 224\n",
    "    patch_size = 4\n",
    "    in_chans = 3\n",
    "    embed_dim = 96\n",
    "\n",
    "    # 创建 PatchEmbed 实例\n",
    "    patch_embed = PatchEmbed(img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "    \n",
    "    # 创建一个模拟的输入图像 (Batch, Channels, Height, Width)\n",
    "    x = torch.randn(1, 3, img_size, img_size)  # 模拟一个 batch size 为 1，大小为 224x224 的输入图像\n",
    "\n",
    "    # 通过 PatchEmbed 得到输出\n",
    "    patch_embed_out = patch_embed(x)\n",
    "    print(f\"PatchEmbed Output Shape: {patch_embed_out.shape}\")\n",
    "    \n",
    "    # 检查输出形状是否正确\n",
    "    expected_patch_embed_shape = (1, (img_size // patch_size) * (img_size // patch_size), embed_dim)\n",
    "    assert patch_embed_out.shape == expected_patch_embed_shape, \\\n",
    "        f\"PatchEmbed 输出形状错误: {patch_embed_out.shape}, 应该为 {expected_patch_embed_shape}\"\n",
    "    \n",
    "    # 定义 SwinTransformerBlock 参数\n",
    "    input_resolution = (img_size // patch_size, img_size // patch_size)\n",
    "    num_heads = 4\n",
    "    window_size = 7\n",
    "    mlp_ratio = 4\n",
    "    shift_size = 0\n",
    "    \n",
    "    # 创建 SwinTransformerBlock 实例\n",
    "    swin_block = SwinTransformerBlock(dim=embed_dim, input_resolution=input_resolution, num_heads=num_heads, window_size=window_size, shift_size=shift_size, mlp_ratio=mlp_ratio)\n",
    "    \n",
    "    # 通过 SwinTransformerBlock 得到输出\n",
    "    swin_block_out = swin_block(patch_embed_out)\n",
    "    print(f\"SwinTransformerBlock Output Shape: {swin_block_out.shape}\")\n",
    "    \n",
    "    # 检查输出形状是否正确\n",
    "    assert swin_block_out.shape == patch_embed_out.shape, \\\n",
    "        f\"SwinTransformerBlock 输出形状错误: {swin_block_out.shape}, 应该为 {patch_embed_out.shape}\"\n",
    "    \n",
    "    print(\"所有测试通过。\")\n",
    "\n",
    "# 运行测试\n",
    "test_swin_transformer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 128, 128])\n",
      "torch.Size([2, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from DyNeXt import DyNeXt\n",
    "import torch\n",
    "\n",
    "model_full = DyNeXt(in_channels=64, K=5, shrink_mode='full')\n",
    "model_half = DyNeXt(in_channels=64, K=5, shrink_mode='half')\n",
    "\n",
    "input_tensor = torch.randn(2, 64, 128, 128)  # batch_size=2, channels=64, height=128, width=128\n",
    "\n",
    "output_full = model_full(input_tensor)\n",
    "print(output_full.shape)\n",
    "output_half = model_half(input_tensor)\n",
    "print(output_half.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envchy",
   "language": "python",
   "name": "envchy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
